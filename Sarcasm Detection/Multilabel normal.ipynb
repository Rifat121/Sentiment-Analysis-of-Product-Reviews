{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EDA Pkgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load Data Viz Pkgs\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# ML Pkgs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss,classification_report\n",
    "\n",
    "### Split Dataset into Train and Text\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Multi Label Pkgs\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'reviews', 'rating', 'sarcastic', 'positive', 'negative',\n",
       "       'neutral', 'admiration', 'angry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"AMAZON sarcasm.csv\", encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title         object\n",
       "reviews       object\n",
       "rating         int64\n",
       "sarcastic      int64\n",
       "positive       int64\n",
       "negative       int64\n",
       "neutral        int64\n",
       "admiration     int64\n",
       "angry          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['angry'] = df['angry'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x235c985ad88>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(df['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(4863)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import neattext as nt\n",
    "import neattext.functions as nfx\n",
    "# Explore For Noise\n",
    "df['reviews'].apply(lambda x:nt.TextFrame(x).noise_scan())\n",
    "# Explore For Noise\n",
    "df['reviews'].apply(lambda x:nt.TextExtractor(x).extract_stopwords())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import regex as re\n",
    "def clean_text(text):\n",
    "    pattern = re.compile('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "    text = pattern.sub('', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"i'm\", \"i am\", text)\n",
    "    text = re.sub(r\"he's\", \"he is\", text)\n",
    "    text = re.sub(r\"she's\", \"she is\", text)\n",
    "    text = re.sub(r\"that's\", \"that is\", text)        \n",
    "    text = re.sub(r\"what's\", \"what is\", text)\n",
    "    text = re.sub(r\"where's\", \"where is\", text) \n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)  \n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)  \n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"won't\", \"will not\", text)\n",
    "    text = re.sub(r\"don't\", \"do not\", text)\n",
    "    text = re.sub(r\"doesn't\", \"does not\", text)\n",
    "    text = re.sub(r\"did't\", \"did not\", text)\n",
    "    text = re.sub(r\"can't\", \"can not\", text)\n",
    "    text = re.sub(r\"it's\", \"it is\", text)\n",
    "    text = re.sub(r\"couldn't\", \"could not\", text)\n",
    "    text = re.sub(r\"have't\", \"have not\", text)\n",
    "    text = re.sub(r\"[,\\\"\\'!@#$%^*(){}?/;`~:<>+=-]\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    text = re.sub(r\"&\", \"and\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for review in df['reviews']:\n",
    "    a = clean_text(review)\n",
    "    reviews.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords,wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "rem = ['not', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \n",
    "       \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \n",
    "       \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'don', \"don't\", \n",
    "       'just', 'too', 'very', 'no', 'nor', 'only', 'own', 'same', 'again', 'against', 'but',]\n",
    "for s in rem:\n",
    "    stopwords.remove(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(review):\n",
    "    ret_str = ''\n",
    "    review = review.split()\n",
    "    for r in review:\n",
    "        if lemmetiz(r) not in stopwords:\n",
    "            ret_str +=lemmetiz(r)\n",
    "            ret_str +=' '\n",
    "    return ret_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmetiz(word):\n",
    "    lem = wordnet_lemmatizer.lemmatize(word,'v')\n",
    "    return lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(nfx)\n",
    "# Explore For Noise\n",
    "# df['reviews'].apply(nfx.remove_stopwords)\n",
    "corpus = df['reviews'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for i in reviews:\n",
    "    p = tokenize(i)\n",
    "    d.append(p)\n",
    "tokens = tfidf.fit_transform(d)\n",
    "tokens = tokens.toarray()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Very Low Accuracy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 150\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(d)\n",
    "sequences = tokenizer_obj.texts_to_sequences(d)\n",
    "lines_pad = pad_sequences(sequences, maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "# Build Features\n",
    "Xfeatures = tfidf.fit_transform(reviews).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['sarcastic', 'positive', 'negative','neutral', 'admiration', 'angry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data \n",
    "X_train,X_test,y_train,y_test = train_test_split(Xfeatures,y,test_size=0.15,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4134, 8493)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Relevence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Our Multi-Label Prob to Multi-Class\n",
    "# binary classficiation\n",
    "binary_rel_clf = BinaryRelevance(MultinomialNB())\n",
    "binary_rel_clf.fit(X_train,y_train)\n",
    "# Predictions\n",
    "br_prediction = binary_rel_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_prediction = br_prediction.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# br_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31917808219178084"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accuracy\n",
    "accuracy_score(y_test,br_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16506849315068492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hamming Loss :Incorrect Predictions\n",
    "# The Lower the result the better\n",
    "hamming_loss(y_test,br_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etate gaussian NB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = BinaryRelevance(GaussianNB())\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.21506849315068494\n",
      "ham_loss 0.30182648401826484\n"
     ]
    }
   ],
   "source": [
    "#accuracy for gauss \n",
    "print(\"accuracy \",accuracy_score(y_test,y_pred))\n",
    "print(\"ham_loss\",hamming_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# clf = BinaryRelevance(RandomForestClassifier(n_estimators=100))\n",
    "# clf.fit(X_train,y_train)\n",
    "# y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy  0.43424657534246575\n",
      "ham_loss 0.1365296803652968\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy \",accuracy_score(y_test,y_pred))\n",
    "print(\"ham_loss\",hamming_loss(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[658,   0],\n",
       "        [ 72,   0]],\n",
       "\n",
       "       [[245, 120],\n",
       "        [ 27, 338]],\n",
       "\n",
       "       [[544,   3],\n",
       "        [ 80, 103]],\n",
       "\n",
       "       [[548,   0],\n",
       "        [178,   4]],\n",
       "\n",
       "       [[583,   0],\n",
       "        [147,   0]],\n",
       "\n",
       "       [[612,   8],\n",
       "        [ 88,  22]]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score\n",
    "\n",
    "multilabel_confusion_matrix(y_test,br_prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.73799127, 0.97169811, 1.        , 0.        ,\n",
       "       0.73333333])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test,br_prediction, average= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: 0.78\n",
      "macro: 0.57\n",
      "weighted: 0.67\n",
      "samples: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"micro: {:.2f}\".format(precision_score(y_test,br_prediction, average= 'micro')))\n",
    "print(\"macro: {:.2f}\".format(precision_score(y_test,br_prediction, average= 'macro')))\n",
    "print(\"weighted: {:.2f}\".format(precision_score(y_test,br_prediction, average= 'weighted')))\n",
    "print(\"samples: {:.2f}\".format(precision_score(y_test,br_prediction, average= 'samples')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro: 0.48\n",
      "macro: 0.37\n",
      "weighted: 0.47\n",
      "samples: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"micro: {:.2f}\".format(metrics.average_precision_score(y_test,br_prediction, average= 'micro')))\n",
    "print(\"macro: {:.2f}\".format(metrics.average_precision_score(y_test,br_prediction, average= 'macro')))\n",
    "print(\"weighted: {:.2f}\".format(metrics.average_precision_score(y_test,br_prediction, average= 'weighted')))\n",
    "print(\"samples: {:.2f}\".format(metrics.average_precision_score(y_test,br_prediction, average= 'samples')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   sarcastic       0.00      0.00      0.00        72\n",
      "    positive       0.74      0.93      0.82       365\n",
      "    negative       0.97      0.56      0.71       183\n",
      "     neutral       1.00      0.02      0.04       182\n",
      "  admiration       0.00      0.00      0.00       147\n",
      "       angry       0.73      0.20      0.31       110\n",
      "\n",
      "   micro avg       0.78      0.44      0.56      1059\n",
      "   macro avg       0.57      0.29      0.32      1059\n",
      "weighted avg       0.67      0.44      0.45      1059\n",
      " samples avg       0.60      0.47      0.51      1059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Rif010\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "output_label = ['sarcastic', 'positive', 'negative','neutral', 'admiration', 'angry']\n",
    "print(classification_report(y_test,br_prediction,target_names=output_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, KFold\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "k_fold = KFold(n_splits = 5 , shuffle = False)\n",
    "k_fold\n",
    "scores = cross_validate(clf, X_train,y_train, cv = k_fold, scoring = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([48.98173785, 69.20634508, 57.06050205, 47.33929777, 47.16790819]),\n",
       " 'score_time': array([0.57898831, 0.95723081, 0.54542375, 0.55640531, 0.56394887]),\n",
       " 'test_accuracy': array([0.4401451 , 0.44619105, 0.41475212, 0.47279323, 0.44915254])}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([5.41730547, 5.23991656, 5.32826185, 5.23438358, 5.27132583,\n",
       "        5.34135628, 5.30242157, 5.25483155]),\n",
       " 'score_time': array([0.31234908, 0.31250405, 0.29674196, 0.31248784, 0.29673266,\n",
       "        0.32798743, 0.29688072, 0.29673243]),\n",
       " 'test_accuracy': array([0.32495164, 0.34816248, 0.31334623, 0.29206963, 0.31914894,\n",
       "        0.31141199, 0.32751938, 0.34689922])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BinaryRelevance(MultinomialNB())\n",
    "k_fold = KFold(n_splits = 8 , shuffle = False)#, random_state = 24)\n",
    "k_fold\n",
    "scores = cross_validate(clf, X_train,y_train, cv = k_fold, scoring = ['accuracy'],error_score='raise')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Chain to preserve label correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.3958904109589041, 'hamming_score': 0.15776255707762557}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(model,mlb_estimator,xtrain,ytrain,xtest,ytest):\n",
    "    # Create an Instance\n",
    "    clf = mlb_estimator(model)\n",
    "    clf.fit(xtrain,ytrain)\n",
    "    # Predict\n",
    "    clf_predictions = clf.predict(xtest)\n",
    "    # Check For Accuracy\n",
    "    acc = accuracy_score(ytest,clf_predictions)\n",
    "    ham = hamming_loss(ytest,clf_predictions)\n",
    "    result = {\"accuracy:\":acc,\"hamming_score\":ham}\n",
    "    return result\n",
    "\n",
    "clf_chain_model = build_model(MultinomialNB(),ClassifierChain,X_train,y_train,X_test,y_test)\n",
    "clf_chain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.2356164383561644, 'hamming_score': 0.24771689497716895}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "clf_chain_model = build_model(gnb,ClassifierChain,X_train,y_train,X_test,y_test)\n",
    "clf_chain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([6.1130569 , 5.28915381, 5.22007012, 5.1248405 , 5.06982136,\n",
       "        5.3000989 , 5.07914829, 5.1082902 , 5.17187047, 5.09144378]),\n",
       " 'score_time': array([0.52578616, 0.468611  , 0.46861696, 0.53876257, 0.50907731,\n",
       "        0.45326281, 0.48436975, 0.50000882, 0.48452687, 0.50000262]),\n",
       " 'test_accuracy': array([0.4057971 , 0.4468599 , 0.39855072, 0.37681159, 0.37046005,\n",
       "        0.36803874, 0.42615012, 0.3874092 , 0.3874092 , 0.40193705])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ClassifierChain(MultinomialNB())\n",
    "k_fold = KFold(n_splits = 10, shuffle = False)#, random_state = 24)\n",
    "k_fold\n",
    "scores = cross_validate(clf, X_train,y_train, cv = k_fold, scoring = ['accuracy'],error_score='raise')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([142.27369809, 143.49477506, 141.18885899, 141.9682703 ,\n",
       "        142.11862016, 144.42072654, 142.21877551, 148.29473019]),\n",
       " 'score_time': array([1.2189033 , 1.21818781, 1.21876001, 1.21859646, 1.20303202,\n",
       "        1.20217967, 1.25014091, 1.21875215]),\n",
       " 'test_accuracy': array([0.49709865, 0.52224371, 0.5106383 , 0.4893617 , 0.53578337,\n",
       "        0.50483559, 0.51356589, 0.48643411])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = ClassifierChain(RandomForestClassifier(n_estimators=100))\n",
    "k_fold = KFold(n_splits = 8 , shuffle = False)#, random_state = 24)\n",
    "k_fold\n",
    "scores = cross_validate(clf, X_train,y_train, cv = k_fold, scoring = ['accuracy'],error_score='raise')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.5123287671232877, 'hamming_score': 0.13219178082191782}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "clf_chain_model = build_model(rf,ClassifierChain,X_train,y_train,X_test,y_test)\n",
    "clf_chain_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Label PowerSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.4383561643835616, 'hamming_score': 0.17077625570776256}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_labelP_model = build_model(MultinomialNB(),LabelPowerset,X_train,y_train,X_test,y_test)\n",
    "clf_labelP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy:': 0.36164383561643837, 'hamming_score': 0.2228310502283105}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_labelP_model = build_model(gnb,LabelPowerset,X_train,y_train,X_test,y_test)\n",
    "clf_labelP_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-21f20aad211f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# rf = RandomForestClassifier(n_estimators=300)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# clf_labelP_model = build_model(rf,LabelPowerset,X_train,y_train,X_test,y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf_labelP_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "# rf = RandomForestClassifier(n_estimators=300)\n",
    "# clf_labelP_model = build_model(rf,LabelPowerset,X_train,y_train,X_test,y_test)\n",
    "rf_pred = clf_labelP_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ec46d907317c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmultilabel_confusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrf_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'rf_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix, precision_score\n",
    "\n",
    "multilabel_confusion_matrix(y_test,rf_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the product suck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Apply On A Simple Ttitle/Question\n",
    "# ex1 = df['reviews'].iloc[98]\n",
    "ex1 = '(https://amazon.com) this website/ is the-best for gadgets'\n",
    "# Make our prediction\n",
    "ex1 = clean_text(ex1)\n",
    "print(ex1)\n",
    "vec_example = tfidf.transform([ex1])\n",
    "rf.predict(vec_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Adapted Algorithm\n",
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'getformat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-378-da27e3054819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLkNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skmultilearn\\adapt\\mlknn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_matrix_in_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lil'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_instances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skmultilearn\\utils.py\u001b[0m in \u001b[0;36mget_matrix_in_format\u001b[1;34m(original_matrix, matrix_format)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSPARSE_FORMAT_TO_CONSTRUCTOR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmatrix_format\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0moriginal_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mmatrix_format\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moriginal_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5485\u001b[0m         ):\n\u001b[0;32m   5486\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5487\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5489\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'getformat'"
     ]
    }
   ],
   "source": [
    "classifier = MLkNN(k=100)\n",
    "classifier.fit(X_train,y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OnevsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf',\n",
       "                 OneVsRestClassifier(estimator=LogisticRegression(solver='sag'),\n",
       "                                     n_jobs=-1))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = Pipeline([('clf',OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=-1)),])\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4328767123287671"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13333333333333333"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = Pipeline([('rf',OneVsRestClassifier(LogisticRegression(solver='lbfgs'), n_jobs=-1)),])\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "ypred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4328767123287671"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13789954337899543"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test,ypred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
